#include <cemm/containers/dynamic_bitset_foreach.h>
#include <cemm/math/Distributions.h>

#include "cemm/bimap/ChessboardBiclusteringLLHEval.h"

namespace cemm { namespace bimap {

ChessboardBiclusteringLLHEval::ChessboardBiclusteringLLHEval(
    DataSignalNoiseCache&   cache,
    const ChessboardBiclustering&  clustering
) : CellsLLHEval( cache.precomputed(), clustering.clusteringData() )
  , _clustering( clustering )
  , _cache( cache )
{
    _cache.update();
}

log_prob_t ChessboardBiclusteringLLHEval::AllCellsDataLLH::operator()(signal_t signal) const
{
    return ( enabledCells ? eval.allCellsDataLLH( signal, -std::numeric_limits<signal_t>::infinity(), true, false ) 
                          : eval.allCellsDataLLH( -std::numeric_limits<signal_t>::infinity(), signal, false, true ) );
}

/**
    Calculate log-likelihood for given signal level, given object and all assay of given probe.
 */
log_prob_t ChessboardBiclusteringLLHEval::cellLLH(
    object_index_t              objIx,
    const OPAProbe&             probe,
    signal_t                    signal
) const {
    return ( cellLLH( signal_params_type( _precomputed.signalParams(), data().object( objIx ),
                                clustering().objectMultiple( objIx ) ),
                      objIx, probe, signal ) );
}

/**
    Calculate log-likelihood for given signal level, given object and all assay of given probe.
 */
log_prob_t ChessboardBiclusteringLLHEval::cellLLH(
    const signal_params_type&   objParams,
    object_index_t              objIx,
    const OPAProbe&             probe,
    signal_t                    signal
) const {
    double lnSignalPdf = 0.0;
    const OPAAssay* pLastAssay = &data().assay( probe.assayIndexes().back() );
    const assay_index_t firstAssayIx = probe.assayIndexes().front();
    const OPAData::celldata_t* celldata = &data().measurement( objIx, firstAssayIx );

    BOOST_ASSERT( !is_unset( signal ) );
    for ( const OPAAssay* pAssay = &data().assay( firstAssayIx ); pAssay <= pLastAssay; ++pAssay ) {
        lnSignalPdf += signal_params_type( objParams, *pAssay, signal )
                          .distribTable( _precomputed.scDistribCache() )
                          .lnPdf( (celldata++)->sc );
        BOOST_ASSERT( is_finite( lnSignalPdf ) );
    }

    LOG_DEBUG2( "Cell (" << objIx << "," << probe.index() << "): signal=" << signal
                << " llh[signal]=" << lnSignalPdf );
    BOOST_ASSERT( lnSignalPdf <= 0 );
    return ( lnSignalPdf );
}

log_prob_t ChessboardBiclusteringLLHEval::blockDataLLH(
    const object_clundex_t      objCluIx,
    const probe_clundex_t       probeCluIx
) const {
    return ( cellsDataLLH( clustering().objectsCluster( objCluIx ).items(),
                           clustering().probesCluster( probeCluIx ).items(),
                           clustering().blockSignal( objCluIx, probeCluIx ) ) );
}

log_prob_t ChessboardBiclusteringLLHEval::cellsDataLLH(
    object_index_t          objectIx,
    const probe_bitset_t&   probes,
    signal_t                signal,
    size_t                  objMultiple
) const {
    double res = 0;
    signal_params_type base( _precomputed.signalParams(), data().object( objectIx ), objMultiple );

    foreach_bit( probe_index_t, probeIx, probes ) {
        const OPAProbe& probe = data().probe( probeIx );
        res += cellLLH( base, objectIx, probe, signal );
    }
    return ( res );
}

/**
    Evaluates the likelihood of data in given cells
    being generated by given signal.
 */
log_prob_t ChessboardBiclusteringLLHEval::cellsDataLLH(
    const object_set_t&     objects,
    probe_index_t           probeIx,
    signal_t                signal,
    size_t                  objMultiple
) const {
    double res = 0;

    const OPAProbe& probe = data().probe( probeIx );
    for ( object_set_t::const_iterator objIt = objects.begin(); objIt != objects.end(); ++objIt ) {
        const object_index_t objIx = *objIt;
        res += cellLLH( signal_params_type( _precomputed.signalParams(), 
                                            data().object( objIx ), 
                                            objMultiple ), 
                        objIx, probe, signal );
    }
    return ( res );
}

/**
    Evaluates the likelihood of data in given cells
    being generated by given signal.
 */
log_prob_t ChessboardBiclusteringLLHEval::cellsDataLLH(
    const object_set_t&         objects,
    const probe_bitset_t&       probes,
    signal_t                    signal,
    const multiple_map_t&       objMultiples
) const {
    double res = 0;

    for ( object_set_t::const_iterator objIt = objects.begin(); objIt != objects.end(); ++objIt ) {
        const object_index_t objIx = *objIt;
        size_t objMult = !objMultiples.empty() && objMultiples[ objIx ] > 0
                       ? objMultiples[ objIx ]
                    // multiples not specified explicitly, get from the current clustering
                       : clustering().objectMultiple( objIx );
        res += cellsDataLLH( objIx, probes, signal, objMult );
    }
    return ( res );
}

#if 0
/**
    Evaluates p-value for hypothesis that block's signal is stronger
    that proposed one -- that is, the sum of probability 
    of all measurements combinations, where each measurement is not greater than actual,
    and one at least one is strictly less = CDF(data) - PDF(data).
 */
log_prob_t ChessboardBiclusteringEval::blockDataLnCdf(
    const object_set_t&         objects,
    const probe_bitset_t&       probes,
    bool                        useNoiseParams,
    bool                        less
) const {
    double lnCdfSum = 0.0;
    double lnPdfSum = 0.0;

    foreach_bit( probe_index_t, probeIx, probes ) {
        const OPAProbe& probe = data().probe( probeIx );
        double lnProbeCdf = 0;
        double lnProbePdf = 0;

        for ( object_set_t::const_iterator objIt = objects.begin(); objIt != objects.end(); ++objIt ) {
            const object_index_t objIx = *objIt;
            const OPACellSignalParams params = useNoiseParams
                    ? clustering().noiseSignalParams() 
                    : cellSignalParams( objIx, clustering().baselineSignalParams().distr().lnPeak 
                                               - 1 * clustering().derivedPriors().signalPrior.sigma );
            const COM_Poisson_Distribution_Calculator  signalPdf( params.distr() );

            const OPAData::celldata_t*  cellDataVec = data().measurements( objIx, probeIx );
            for ( size_t i = 0; i < probe.assays().size(); i++ ) {
                OPAData::celldata_t  cellData = cellDataVec[ i ];
                log_prob_t lnPdf = signalPdf.lnPdf( cellData );
                log_prob_t lnCdf = less
                             ? signalPdf.lnCdf_P( cellData ) 
                             : ( cellData > 0 ? signalPdf.lnCdf_Q( cellData - 1 ) : 0 );
                BOOST_ASSERT( !gsl_isnan( lnCdf ) && ( less || gsl_finite( lnCdf ) ) );
                LOG_DEBUG2( "Cell[" << ( useNoiseParams ? "N" : "S" ) << "](" << objIx << "," << *assayIt 
                             << ") peak=" << signalPdf.lnPeak 
                             << " cdf=" << lnCdf << " pdf=" << lnPdf );
                lnProbeCdf += lnCdf;
                lnProbePdf += lnPdf;
            }
        }
        LOG_DEBUG2( "Probe[" << ( useNoiseParams ? "N" : "S" ) << "](" << probeIx 
                    << ") cdf=" << lnProbeCdf << " pdf=" << lnProbePdf );
        lnCdfSum += ( lnProbePdf + 1E-10 < lnProbeCdf 
                    ? lnProbeCdf + gsl_log1p( -exp( lnProbePdf - lnProbeCdf ) ) 
                    : gsl_neginf() );
        BOOST_ASSERT( !gsl_isnan( lnCdfSum ) );
        lnPdfSum += lnProbePdf;
    }
    LOG_DEBUG2( "Sum[" << ( useNoiseParams ? "N" : "S" ) << "]=" << lnCdfSum );
    // return log( cdf - pdf )
    return ( lnCdfSum ); //( lnPdfSum < lnCdfSum ? lnCdfSum + gsl_log1p( -exp( lnPdfSum - lnCdfSum ) ) : gsl_neginf() );
}
#endif

log_prob_t ChessboardBiclusteringLLHEval::allCellsDataLLH(
    bool    sumEnabledCrosses,
    bool    sumDisabledCrosses
) const {
    double  lnPdf = 0.0;

    for ( object_clundex_t objCluIx = 0; objCluIx < clustering().objectsClusters().size(); objCluIx++ ) {
        for ( probe_clundex_t probeCluIx = 0; probeCluIx < clustering().probesClusters().size(); probeCluIx++ ) {
            bool crossEnabled = clustering().isBlockEnabled( objCluIx, probeCluIx );
            // filter cells by coverage according to filter and calculate lambda
            if ( ( crossEnabled && !sumEnabledCrosses )
              || ( !crossEnabled && !sumDisabledCrosses ) )      continue;
            // substitute current basic signal level with the new one
            if ( crossEnabled ) {
                signal_t signal = clustering().blockSignal( objCluIx, probeCluIx );
                if ( is_unset( signal ) ) THROW_RUNTIME_ERROR( "allCellsDataLLH(): signal for ("
                    << objCluIx << ", "
                    << probeCluIx << ") is not set" );
                lnPdf += cellsDataLLH( clustering().objectsCluster( objCluIx ).items(),
                                       clustering().probesCluster( probeCluIx ).items(),
                                       signal,
                                       clustering().objectMultiples()
                                     );
            }
            else {
                lnPdf += cellsNoiseLLH( clustering().noiseParams(),
                                        clustering().objectsCluster( objCluIx ).items(),
                                        clustering().probesCluster( probeCluIx ).items() );
            }
        }
    }
    BOOST_ASSERT( lnPdf <= 0 );
    return ( lnPdf );
}

log_prob_t ChessboardBiclusteringLLHEval::allCellsDataLLH(
    signal_t    baselineSignal,
    prob_t      zeroRate,
    bool        sumEnabledCrosses,
    bool        sumDisabledCrosses
) const {
    double  lnPdf = 0.0;

    GeometricDistribution noiseParams = GeometricDistribution::BySuccessRate( zeroRate, 0 );

    for ( object_clundex_t objCluIx = 0; objCluIx < clustering().objectsClusters().size(); objCluIx++ ) {
        for ( probe_clundex_t probeCluIx = 0; probeCluIx < clustering().probesClusters().size(); probeCluIx++ ) {
            bool crossEnabled = clustering().isBlockEnabled( objCluIx, probeCluIx );
            // filter cells by coverage according to filter and calculate lambda
            if ( ( crossEnabled && !sumEnabledCrosses )
              || ( !crossEnabled && !sumDisabledCrosses ) )      continue;
            // substitute current basic signal level with the new one
            if ( crossEnabled ) {
                signal_t signal = clustering().blockSignal( objCluIx, probeCluIx );
                if ( is_unset( signal ) ) THROW_RUNTIME_ERROR( "allCellsDataLLH(): signal for ("
                    << objCluIx << ", "
                    << probeCluIx << ") is not set" );
                lnPdf += cellsDataLLH( clustering().objectsCluster( objCluIx ).items(),
                                       clustering().probesCluster( probeCluIx ).items(),
                                       baselineSignal,
                                       clustering().objectMultiples()
                                     );
            }
            else {
                lnPdf += cellsNoiseLLH( noiseParams,
                                        clustering().objectsCluster( objCluIx ).items(),
                                        clustering().probesCluster( probeCluIx ).items() );
            }
        }
    }
    BOOST_ASSERT( lnPdf <= 0 );
    return ( lnPdf );
}

/**
    Calculate log-likelihood for block being in off-state.
 */
log_prob_t ChessboardBiclusteringLLHEval::cellsNoiseLLH(
    const CellsLLHEval::noise_params_type& noiseParams, 
    const object_set_t&     objects, 
    const probe_bitset_t&   probes
) const {
    double res = 0;
    size_t  i = 0;
    std::vector<size_t> scCounts( objects.size(), 0 );
    size_t  scSum = 0;
    size_t  scObjsNE = 0;

    for ( object_set_t::const_iterator objIt = objects.begin(); objIt != objects.end(); ++objIt ) {
        const object_index_t objIx = *objIt;
        foreach_bit( probe_index_t, probeIx, probes ) {
            const OPAProbe& probe = data().probe( probeIx );
            scCounts[ i ] += data().measurementSum( objIx, probeIx );

            const OPAData::celldata_t* celldata = data().measurements( objIx, probeIx );
            const OPAData::celldata_t* endCelldata = celldata + probe.assayIndexes().size();
            for ( ; celldata < endCelldata; ++celldata ) {
                res += noiseParams( celldata->sc );
            }

            BOOST_ASSERT( !is_unset( res ) );
            LOG_DEBUG2( "Cell (" << objIx << "," << probeIx << 
                        "): noiseRate=" << ( 1.0 - noiseParams.successRate ) 
                        << " llh=" << res );
        }
        if ( scCounts[ i ] > 0 ) scObjsNE++;
        scSum += scCounts[ i ];
        i++;
    }
    // add combinatorial part to the probability:
    // 1. possibilities to select scObjNE different objects from the universe
    res += gsl_sf_lnchoose( data().objectsUniverseSize(), scObjsNE );
    // 2. possibilities to distribute scSum spectral counts among scObjNE objects
    res += ln_factorial( scSum );
    for ( std::size_t i = 0; i < scCounts.size(); i++ ) {
        if ( scCounts[i] > 0 ) res -= ln_factorial( scCounts[i] );
    }
    // 3. probability to pick a sequence of scSum objects from the universe (without replacement)
    res -= scSum * log( data().objectsUniverseSize() );
    BOOST_ASSERT( std::isfinite( res ) );
    return ( res );
}

/**
 *  Calculates the LLH that block of cells is either in enabled or disabled probe.
 *
 *  P(N<=n|noise)*P(N<=|min_signal) if enabled
 *  P(N>=n|noise)*P(N>|min_signal) if disabled
 */
log_prob_t BlockEnablementDataLLH::operator()(
    bool isEnabled
) const {
    return ( isEnabled ? cache.signalLLH( objects, probes )
                       : cache.noiseLLH( objects, probes ) );
}

} }